{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd3b39e-2e65-4aa1-86cd-8a8880ca2fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this program, I train on Balrog injections to get relations to the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb54a59e-dc5b-478e-a13b-73d2583d9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The magnitude bins I used are:\n",
    "\n",
    "# less than 20\n",
    "\n",
    "# 20 - 22\n",
    "\n",
    "# 22 - 23\n",
    "\n",
    "# 23 - 24\n",
    "\n",
    "# 24 - 25\n",
    "\n",
    "# 25 - 26\n",
    "\n",
    "# greater than 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e0647a-dfbd-4553-8a33-8e3bf6f7cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "from numpy import loadtxt\n",
    "import fitsio\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import Config\n",
    "from scipy import interpolate as inter\n",
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daaebe85-f60e-4920-96ec-b808e76f4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 4096 # Resolution of the heal pixels\n",
    "sigma = 0.5 # Sigma used for gaussian weighting\n",
    "numBins = 100 # Number of bins to use\n",
    "perVar = 0.98 # Percent of the variance to be captured\n",
    "perMap = 0.625 # Percent of the PC maps to use, adjust this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0961b2d-23f2-41df-be3d-8538c2ec9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "condMean = [] # Mean value of the conditions (to be used later in normalization)\n",
    "condStds = [] # Standard deviation of the conditions (to be used later in normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8b64d96-87df-4238-bfe1-044f90cb98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validPix = fitsio.read(\"/hdfs/bechtol/balrog/y3/y3a2_survey_conditions_maps/Kyle_Stuff/training/Valid_\"+str(res)+\"_Pixels.fits\")['PIXEL']\n",
    "# Boolean alternative to validPix allows for some things to be easier.\n",
    "pixCheck = np.full(12*(res**2), False, dtype = bool)\n",
    "pixCheck[validPix] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8112ef3-d8df-483b-9b49-4b2914ff806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the actual file containing all of the balrog data\n",
    "balrFile = '/afs/hep.wisc.edu/bechtol-group/MegansThings/balrog_detection_catalog_sof_run2_stars_v1.4_avg_added_match_flags.fits'\n",
    "# This reads in all of the data. Most of these are just flags, the only pieces that get used much outside\n",
    "# of filtering are detected, true_ra and true_dec which get used to convert into healPixels.\n",
    "balrData = fitsio.read(balrFile, columns = ['detected', 'true_ra', 'true_dec',\n",
    "                                            'flags_foreground', 'flags_badregions', 'flags_footprint',\n",
    "                                            'match_flag_1.5_asec', 'true_g_Corr', 'true_gr_Corr'])\n",
    "\n",
    "# These are in degrees which is why lonlat is set to True in the next cell.\n",
    "balrRA = balrData['true_ra']\n",
    "balrDEC = balrData['true_dec']\n",
    "# This is used for detection rates, each point is either a 0 (no detection) or a 1 (detection)\n",
    "balrDETRepeats = balrData['detected']\n",
    "# Everything from here on out is simply used in order to filter the data\n",
    "FOREGROUND = balrData['flags_foreground']\n",
    "BADREGIONS = balrData['flags_badregions']\n",
    "FOOTPRINT = balrData['flags_footprint']\n",
    "ARCSECONDS = balrData['match_flag_1.5_asec']\n",
    "# Magnitudes are used for both color and brightness cuts.\n",
    "GMAG = balrData['true_g_Corr']\n",
    "RMAG = balrData['true_g_Corr'] - balrData['true_gr_Corr']\n",
    "\n",
    "# This is used to filter out any injections that either weren't detected or had flags raised.\n",
    "cutIndices = np.where((FOREGROUND == 0) & \n",
    "                      (BADREGIONS < 2) & \n",
    "                      (FOOTPRINT == 1) & \n",
    "                      (ARCSECONDS < 2) &\n",
    "                      # Color cuts\n",
    "                      (GMAG - RMAG >= -0.3) &\n",
    "                      (GMAG - RMAG <= 1) &\n",
    "                      # Magnitude cuts\n",
    "                      (GMAG > 26))[0]# &\n",
    "                      # (GMAG <= 26))[0]\n",
    "\n",
    "# This reduced the data down to the actually valid pixels.\n",
    "balrDETRepeats = balrDETRepeats[cutIndices]\n",
    "balrRA = balrRA[cutIndices]\n",
    "balrDEC = balrDEC[cutIndices]\n",
    "\n",
    "# This converts the RA and DEC values from above to healpixels so we can compare to the sky condition.\n",
    "balrPIXRepeats = hp.ang2pix(res, balrRA, balrDEC, lonlat = True, nest = True)\n",
    "\n",
    "# This sorts by the pixel in order to make following methods more efficient.\n",
    "sortInds = balrPIXRepeats.argsort()\n",
    "balrPIXRepeats = balrPIXRepeats[sortInds[::1]]\n",
    "balrDETRepeats = balrDETRepeats[sortInds[::1]]\n",
    "\n",
    "# These are indices that will be looping through the pixStar and starPix arrays in parallel.\n",
    "uniqInd = 0\n",
    "balrInd = 0\n",
    "\n",
    "# This will be used to store the number of stars at each pixel.\n",
    "balrPIX = np.unique(balrPIXRepeats) # The unique pixels, with no repeats.\n",
    "balrDET = np.zeros_like(balrPIX)\n",
    "balrINJ = np.zeros_like(balrPIX)\n",
    "\n",
    "while balrInd < len(balrPIXRepeats):\n",
    "    if balrPIX[uniqInd] == balrPIXRepeats[balrInd]: # If the pixels match up in the arrays.\n",
    "        balrDET[uniqInd] += balrDETRepeats[balrInd] # Add one if there was a detection at this location.\n",
    "        balrINJ[uniqInd] += 1                # Add one to the corresponding spot in the balStar array.\n",
    "        balrInd += 1                         # Add one to the starInd to see if the next index in starPix is also the same.\n",
    "        # Since the last index of pixStar and starPix are the same, starInd will increase the last time through the loop,\n",
    "        # making this the index that we must restrict in the while loop.\n",
    "    else:\n",
    "        uniqInd += 1 # If the pixels are no longer the same, increase the index you check in the pixStar array.\n",
    "        \n",
    "balrDET = balrDET[pixCheck[balrPIX]]\n",
    "balrINJ = balrINJ[pixCheck[balrPIX]]\n",
    "balrPIX = balrPIX[pixCheck[balrPIX]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f066e7de-3eca-4c86-8ffb-07c0277ba49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads in all of the file names of the survey conditions\n",
    "directory = '/hdfs/bechtol/balrog/y3/y3a2_survey_conditions_maps/Kyle_Stuff/training/'+str(res)+'_'\n",
    "conditions = Config.conditions\n",
    "balrCondMaps = []\n",
    "\n",
    "# This loops over every condition file\n",
    "for cond in conditions:\n",
    "    condData = fitsio.read(directory + cond + '.fits') # This reads in the data\n",
    "    condSigExt = np.full(12*(res**2), -1.6375e+30) # Gives a default value\n",
    "    condSigExt[validPix] = condData['SIGNAL'] # Changes all valid pixels to their corresponding signals\n",
    "    condSigExt[np.where(condSigExt == -1.6375e+30)[0]] = hp.UNSEEN # Masks all non valid pixels\n",
    "    balrCondMaps.append(condSigExt[balrPIX]) # Only stores the values that are in pixels with injections\n",
    "\n",
    "balrCondMaps = np.array(balrCondMaps, dtype = object) # Converts to an array\n",
    "\n",
    "# Stores the original data for later comparisons\n",
    "originalBalrDET = balrDET\n",
    "originalBalrINJ = balrINJ\n",
    "aveEff = np.sum(originalBalrDET) / np.sum(originalBalrINJ) # Average efficiency of detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad835433-f3fc-4931-972d-ae968a7f6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "balrStanMaps = []\n",
    "# This standardizes every map as a first step of PCA\n",
    "for i in range(len(balrCondMaps)):\n",
    "    # Store mean and std dev for later use.\n",
    "    condMean.append(np.average(balrCondMaps[i]))\n",
    "    condStds.append(np.std(balrCondMaps[i]))\n",
    "    balrStanMaps.append((balrCondMaps[i] - np.average(balrCondMaps[i])) / np.std(balrCondMaps[i]))\n",
    "    \n",
    "balrStanMaps = np.array(balrStanMaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45190a67-508b-40e9-ab00-bce3dfdd9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives the covariance matrix of the standardized maps\n",
    "# Bias is true since the variance of each individual standardized map should be 1\n",
    "cov = np.cov(balrStanMaps.astype(float), bias = True)\n",
    "\n",
    "# This gives the eigenvalues and vectors of the covariance matrix\n",
    "evalues, evectors = np.linalg.eig(cov)\n",
    "\n",
    "# This cuts after the specified percentage of the variance has been achieved\n",
    "for i in range(len(evalues)):\n",
    "    if np.sum(evalues[0:i+1]) / np.sum(evalues) >= perVar:\n",
    "        cutoff = i + 1\n",
    "        break\n",
    "featVec = evectors[0:cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04262f8e-0eb8-4cc7-9ee3-5971a4223024",
   "metadata": {},
   "outputs": [],
   "source": [
    "balrRedMaps = np.matmul(featVec, balrStanMaps) # Reduces the maps to PCA maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9aac320-3ff5-4c7c-ac58-2b60b28638a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviations will once more be stored for later use.\n",
    "# Maps are reduced to standard deviation of 1 for consistent x values in the following steps.\n",
    "redStds = []\n",
    "for i in np.arange(len(balrRedMaps)):\n",
    "    redStds.append(np.std(balrRedMaps[i]))\n",
    "    balrRedMaps[i] = balrRedMaps[i]/np.std(balrRedMaps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16cbe80e-a483-4355-8dbb-40b414d329b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal of this method is to find the index of the map that has the largest impact on detection rates.\n",
    "def mostSigPCMap(redMaps, detBALR, balrINJ = balrINJ, sigma = sigma, numBins = 100):\n",
    "    \n",
    "    maxAdjustment = []\n",
    "\n",
    "    for i in range(len(redMaps)):\n",
    "        \n",
    "        onePC = redMaps[i] # Load up a PC map\n",
    "\n",
    "        x = np.linspace(-3, 3, 100) # xValues for plot, goes out to 3 standard deviation.\n",
    "        y = []\n",
    "        \n",
    "        for xi in x:\n",
    "            # Gaussian weighting the values close by to each x value.\n",
    "            totDet = np.sum(detBALR * np.exp(-1*(((onePC.astype(float) - xi) / sigma)**2)))\n",
    "            totInj = np.sum(balrINJ * np.exp(-1*(((onePC.astype(float) - xi) / sigma)**2)))\n",
    "            y.append((totDet / totInj) / aveEff)\n",
    "\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # Make the error the sum of the squared difference between the binned values and 1.\n",
    "        maxAdjustment.append(np.sum((y - 1)**2))\n",
    "        \n",
    "    maxAdjustment = np.array(maxAdjustment)\n",
    "    \n",
    "    mostSigIndex = np.where(maxAdjustment == np.max(maxAdjustment))[0]\n",
    "    \n",
    "    return mostSigIndex[0] # Return wherever the error is the largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff3bf3d-de73-4fcc-80d7-2e31cb4f7eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "balrDET = originalBalrDET\n",
    "yValues = []\n",
    "corrIndices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dee78316-9733-4fc0-94cd-e10882162d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimBalrRedMaps = np.copy(balrRedMaps)\n",
    "\n",
    "# Iterate however many times is called for.\n",
    "iterations = int(perMap * len(balrRedMaps))\n",
    "\n",
    "for _ in np.arange(iterations):\n",
    "    \n",
    "    # Figure out the most significant map.\n",
    "    index = mostSigPCMap(trimBalrRedMaps, balrDET)\n",
    "    \n",
    "    # Store this index for later use.\n",
    "    corrIndices.append(index)\n",
    "    \n",
    "    # Use this map to generate values.\n",
    "    onePC = trimBalrRedMaps[index]\n",
    "    \n",
    "    x = np.linspace(-3, 3, 100)\n",
    "    y = []\n",
    "\n",
    "    for xi in x:\n",
    "        # Gaussian weight the values when determining y Values.\n",
    "        totDet = np.sum(balrDET * np.exp(-1*(((onePC.astype(float) - xi) / sigma)**2)))\n",
    "        totInj = np.sum(balrINJ * np.exp(-1*(((onePC.astype(float) - xi) / sigma)**2)))\n",
    "        y.append((totDet / totInj) / aveEff)\n",
    "\n",
    "    y = np.array(y)\n",
    "    \n",
    "    yValues.append(y)\n",
    "    \n",
    "    # Generate an interpolation function with constant extrapolation around the ends.\n",
    "    f = inter.interp1d(x, y, bounds_error = False, fill_value = (y[0], y[-1]))\n",
    "\n",
    "    correction = f(trimBalrRedMaps[index].astype('float'))\n",
    "\n",
    "    correction = 1 / correction\n",
    "\n",
    "    # Apply correction and remove whichever principal component was used.\n",
    "    balrDET = balrDET * correction\n",
    "\n",
    "    pcMapCutoff = np.full(len(trimBalrRedMaps), True, dtype = bool)\n",
    "    pcMapCutoff[index] = False\n",
    "    trimBalrRedMaps = trimBalrRedMaps[pcMapCutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a2bde4-0384-4d64-ba27-32de783df857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used to find th original indices used accounting for the fact that maps were removed throughout.\n",
    "actualCorrIndices = []\n",
    "originalIndices = np.arange(len(balrRedMaps))\n",
    "\n",
    "for index in corrIndices:\n",
    "    actualCorrIndices.append(originalIndices[index])\n",
    "    originalIndices = np.delete(originalIndices, index)\n",
    "    \n",
    "actualCorrIndices = np.array(actualCorrIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93fbf2b0-22f0-4059-8bb9-730fb4f1a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/hdfs/bechtol/balrog/y3/y3a2_survey_conditions_maps/Kyle_Stuff/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecefaf71-69a8-4e3a-a746-6f83e0a1c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These next bits all save data, with different formatting when the data size is small.\n",
    "savetxt(file + str(res) + '_Inter_Blue_>26_Means.csv', condMean, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b58667b8-8921-4844-b0e4-326317a6eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt(file + str(res) + '_Inter_Blue_>26_Standard_Deviations.csv', condStds, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5060b717-ac74-4518-8d4f-14e4aceaabd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt(file + str(res) + '_Inter_Blue_>26_Red_Standard_Deviations.csv', redStds, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf4b43b5-bb0f-44bb-ab09-c9bfe24e6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt(file + str(res) + '_Inter_Blue_>26_Indices.csv', actualCorrIndices, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4737353-802c-4f98-96d9-650ff0d11f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt(file + str(res) + '_Inter_Blue_>26_Feature_Vectors.csv', featVec, delimiter='\\t', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf6e8924-e33d-4840-9691-93fe695d1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table = Table()\n",
    "for i in np.arange(len(actualCorrIndices)):\n",
    "    my_table[str(actualCorrIndices[i])] = yValues[i]\n",
    "my_table.write(file + str(res) + '_Inter_Blue_>26_y_Values' + '.fits', overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947bcd75-605e-423b-8283-4a123a800d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
